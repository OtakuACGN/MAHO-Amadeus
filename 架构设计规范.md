# 系统架构设计规范

主要记录了整一个项目大致的框架和思路，有些细节有差错请以代码为准。
代码最好设计的简洁易用，不要去考虑不存在的需求。

## 后端架构

后端采用组件化设计，通过统一的管理器和标准的输出队列与外部通信。

### 组件体系
-   组件管理器 (Components.py)：
    -   提供统一的接口对外暴露功能，屏蔽底层具体实现的差异（如不同的 LLM、TTS 模型）。
    -   允许每个组件配置自己的具体实现方法。
    -   还包括了配置的存储，虽然理论上这个功能应该分开单独做，配置文件。有一个backend下的是默认配置文件，但是如果data目录下还有一个配置文件，那么会优先读取data目录下的配置文件。

-   LLM (LLMService.py)：
    -   职责：处理自然语言生成任务。

-   TTS (TTSService.py)：
    -   职责：将文本转换为音频。
    -   锁机制：采用队列锁控制并发访问。锁实现位于 `core/util/resource_lock.py` 的 `ResourceLock` 类。每个角色可提前申请队列，只有队列头部角色才能执行合成，可以通过配置文件决定是否启用此功能。
    -   设计意图：锁以**整段对话**为粒度（而非单句）。角色在 `chat()` 开始时 `reserve()` 占位，期间每句 `acquire()` 仅检查队首不阻塞，全部说完后 `release()` 释放。这样确保"即将演出的角色"独占 TTS 资源，避免多角色同时生成导致前端乱序或资源浪费。

-   翻译 (TranslatorService.py)：
    -   职责：处理文本翻译任务。

-   ASR (ASRService.py)：
    -   职责：将语音转换为文本。

### 角色系统
-   角色组件 (Character.py)：
    -   具体流程：触发 Chat 函数 → 调用 LLM → LLM 回复分片放入队列 → 队列内容按标点分割供 TTS 处理 → TTS 生成音频 → 经 base64 编码后放入输出队列。
    -   Chat 接口：核心交互入口。
        -   输入：用户或剧本的指令或对话。
        -   行为：调用 Chat 函数，角色自动申请资源（LLM、TTS、翻译等组件），生成数据分片并放入队列。
        -   输出：将生成的回复推送到 `output_queue` 队列。

### 导演与剧本
-   导演 (Director.py)：
    -   系统总控与桥梁：连接用户与角色的核心枢纽。
    -   职责：
        -   决定当前由哪些角色进行回话（调度逻辑）。
        -   作为一个中间件处理各类转发工作。
        -未来扩展：可能承担特殊的游戏化逻辑 or 系统级干预。
-   剧本 (Script.py)：
    -   职责：
        -   记录上下文关系 (Context)。
        -   维护台词表 (Lines)。
        -   未来扩展：作为世界观记录载体，存储设定集与背景信息。

### 输出数据流
后端的输出不是一次性的，而是基于流式传输 (Streaming) 的数据包流。
-   数据结构：
    -   Start Packet：流开始的数据包（包含 meta 信息）。
    -   Content Packets：中间内容包（Type 区分：文本、思考内容、音频分片、扩展类型等）。
    -   End Packet：流结束的标记包。
-   抽象定义：整个回复过程被抽象为一个完整的数据流包组。




## 前端架构
前端严格遵循 MVVM 模式，强调 Store 作为唯一真实数据源。

### 核心通信桥梁
-   演出队列 (performance.ts)：
    -   前端与后端通信的唯一业务桥梁，只存储数据，不包含任何 UI 逻辑。
    -   结构：一个列表，里面的每一个对象都是一次演出，对象长这样：
        -   {
                character: 'maho',
                thinkText: '',
                displayedText: '',
                audioChunks: [],
                isThinkingComplete: false,
                isSegmentComplete: false,
            }
    -   后端会通过websoket传输有类型的片段，以下是不同类型的处理逻辑：
        -   `start`：初始化并向队列末尾推入一个新的演出片段对象。
        -   `thinkText`：增量追加流式文本到思考内容缓冲区。
        -   `text`/`audio`：接收正文文本或音频分片，并立即标记思考阶段完成以切换演出状态。
        -   `end`：标记文本与音频全部接收完毕，封存当前片段并停止接收新流。
        
### 前端导演
-   前端导演 (director.ts)：
    -   作为前端的总控，负责把演出队列的数据渲染到各个 Store 上。
    -   状态机 (State Machine) 设计：
        1.  输入待机状态 (Input Standby)
            -   条件：队列为空且上一次演出结束。
            -   行为：Dialog Store 开启输入模式，显示输入光标 (`showCaret = true`)，等待用户输入发送给后端。
        2.  演出状态 (Performance)
            -   条件：队列中有数据，且进入处理流程。
            -   核心逻辑：同步队列首位元素的状态。
            -   Dialog 行为：
                -   使用队列中的角色名更新 `currentName`。
                -   打字机效果：拥有一个速度变量（字/秒）。光标不显示 (`showCaret = false`)。
                -   阶段一：遍历并逐字添加“思考文本 (thinkText)”到渲染窗口。
                -   阶段二：思考文本演示完毕后，清空思考文本，开始逐字添加“普通文本 (displayedText)”。
            -   Audio 行为：
                -   按照索引顺序提取 `audioChunks` 并推送到 Audio Store 进行播放。
        3.  等待状态 (Waiting)
            -   条件：当前演出项的所有内容（文本+音频）播放完毕。
            -   行为：
                -   显示光标 (`showCaret = true`)，提示交互。
                -   点击交互：用户点击页面任意位置触发。
                    -   若队列有后续数据 -> 进入 演出状态。
                    -   若队列为空 -> 进入 输入待机状态。

### 渲染组件
每个 Store 对应一个具体的渲染组件，尽量不要在这个组件引用其他的store导致互相深度耦合逻辑。

-   Dialog Store (dialog.ts)：
    -   canInput：是否允许输入
    -   showCaret：是否显示输入光标
    -   showDialog：对话框显示状态
    -   currentName：当前角色名称
    -   thinkText：思考内容文本
    -   displayedText：当前显示的对话文本

-   Stage Store (stage.ts)：
    -   主要负责一整个背景还有人物的立绘显示。
    -   characters：角色配置列表。
        -   id: 角色唯一标识。
        -   name: 角色名称。
        -   modelPath: 模型配置文件的路径。
        -   scale: 模型缩放比例。
        -   position: 模型中心点位置 (x, y)。
        -   mouthOpen: 嘴巴张开幅度 (0到1 之间的浮点数)，用于实时口型同步。
    -   background：舞台背景配置。
        -   path：背景图像的路径。
        -   alpha：背景透明度。
        -   scaleMode：背景缩放模式 (cover/contain/stretch)。

-   Audio Store (audio.ts)：
    -   职责：全局唯一音频播放控制中心。
    -   状态：维护 `mouthOpen` (实时口型值) 与 `speakingCharacterId` (当前发言角色)。
    -   行为：封装 `AudioPlayer` 实现音频解码与播放，通过回调实时更新口型状态并同步驱动 `Stage Store` 的模型变换。

-   VAD Store (vad.ts)：
    -   职责：管理录音、VAD 检测状态、音频分片发送。




## 语音交互回路

前端 VAD 检测语音起止，实时推送音频分片至后端 ASR。识别完成后通过 `_dispatch_chat` 统一进入导演调度流程，与文本输入同一路径处理。流程：

1. **前端**：VAD 触发 → 采集 PCM → Base64 编码 → WebSocket 推送（`type: audio`）
2. **后端 ASR**：接收分片 → 流式识别 → 返回文本 → 回调 `_dispatch_chat`
3. **后续流程**：与文本输入完全一致（导演决策 → 角色生成 → 前端演出）




## 接口协议示例 (Protocol)

后端 -> 前端 WebSocket 消息流示例：

```json
// 1. 开始信号
{ "type": "start", "character": "maho", "requestId": "uuid..." }

// 2. 思考内容 (Stream)
{ "type": "thinkText", "character": "maho", "data": "嗯..." }

// 3. 文本内容 (Stream)
{ "type": "text", "character": "maho", "data": "嗯..." }
{ "type": "text", "character": "maho", "data": "也是命运石之门的选择吗？" }

// 4. 音频内容 (Stream)
{ "type": "audio", "character": "maho", "data": "base64...", "is_final": false }
{ "type": "audio", "character": "maho", "data": "base64...", "is_final": true }

// 5. 结束信号
{ "type": "end", "character": "maho" }
```
